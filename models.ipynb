{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4e5b6350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Invalid requirement: '#'\n"
     ]
    }
   ],
   "source": [
    "#!pip install keras\n",
    "#!pip install tensorflow\n",
    "#!pip install torch==1.4.0\n",
    "#!pip install sentencepiece\n",
    "!pip install --upgrade transformers==3.0.2 # the authors probably used version 3.0.2\n",
    "# !pip install contractions\n",
    "# !pip install unidecode\n",
    "# !pip install contractions\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3324dba7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n",
      "3.0.2\n"
     ]
    }
   ],
   "source": [
    "# the basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "import logging\n",
    "# import random\n",
    "\n",
    "# data cleaning\n",
    "# import re\n",
    "# import contractions as ct\n",
    "# import string\n",
    "# import unidecode \n",
    "\n",
    "# math + machine learning\n",
    "from scipy.stats import spearmanr\n",
    "from math import floor, ceil\n",
    "from tqdm import tqdm # for nice progress meters\n",
    "import sklearn\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import nltk \n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow import keras \n",
    "\n",
    "# import keras model and layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, Concatenate\n",
    "# import tensorflow.keras.utils.Sequence\n",
    "# from transformers import *\n",
    "import transformers\n",
    "from transformers import TFBertModel, BertTokenizer\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "# from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# viz\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "print(tf.__version__)\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58893f31",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "- 1-layer NN that predicts binary humor label using pre-trained BERT embeddings of 10K short jokes/non-jokes\n",
    "- inputs: input IDs, attention masks, and token type IDs from pre-trained BERT tokenizer\n",
    "- outputs: probability of a short text being humorous (p > 0.5 = humorous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0054db98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "### basic model architecture ###\n",
    "\n",
    "INPUT_LEN = 100 # same as MAX_LENGTH in bertembeddings.py\n",
    "\n",
    "x1 = Input(shape=(INPUT_LEN,), dtype=tf.int32, name='input_ids')\n",
    "x2 = Input(shape=(INPUT_LEN,), dtype=tf.int32, name='attention_masks')\n",
    "x3 = Input(shape=(INPUT_LEN,), dtype=tf.int32, name='token_type_ids')\n",
    "\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "bert_embeddings = bert_model(x1, attention_mask=x2, token_type_ids=x3)\n",
    "pooled_embeddings = bert_embeddings[1]\n",
    "\n",
    "yhat = Dense(1, activation='sigmoid', name='output')(pooled_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ecfa438e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "9/9 [==============================] - 83s 4s/step - loss: 1.0951 - accuracy: 0.5400\n",
      "Epoch 2/5\n",
      "9/9 [==============================] - 34s 4s/step - loss: 0.7284 - accuracy: 0.4600\n",
      "Epoch 3/5\n",
      "9/9 [==============================] - 34s 4s/step - loss: 0.7281 - accuracy: 0.5400\n",
      "Epoch 4/5\n",
      "9/9 [==============================] - 39s 4s/step - loss: 0.8475 - accuracy: 0.4800\n",
      "Epoch 5/5\n",
      "9/9 [==============================] - 38s 4s/step - loss: 0.7856 - accuracy: 0.4200\n"
     ]
    }
   ],
   "source": [
    "### intialize and compile model ###\n",
    "base_model = Model([x1, x2, x3], [yhat], name='baseline')\n",
    "base_model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "### train model ###\n",
    "# load data\n",
    "inputs = np.load(\"testrun_model_train_inputs.npz\", allow_pickle=True)\n",
    "X = list(inputs.values())[-3:]\n",
    "data = pd.read_csv('clean_dataset.csv')\n",
    "y_train, y_test = data['humor'][:160000][:50], data['humor'][160000:][:50]\n",
    "\n",
    "# fit model\n",
    "base_hist = base_model.fit(X, y_train.values, epochs=5, batch_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ef88a6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guessing the dominant class gives an accuracy of 0.58\n"
     ]
    }
   ],
   "source": [
    "# the baseline model does worse than simply guessing the dominant class\n",
    "dom_acc = y_train.mean() if y_train.mean() > 0.5 else 1 - y_train.mean()\n",
    "print(\"Guessing the dominant class gives an accuracy of {}\".format(round(dom_acc,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3764c19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model always guesses the dominant class\n",
    "(base_model.predict(X) > 0.5).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "74f33239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 52.0\n",
      "F1 score = 0.0\n"
     ]
    }
   ],
   "source": [
    "### predict test data and print test accuracy ###\n",
    "test_inputs = np.load(\"testrun_model_test_inputs.npz\", allow_pickle=True)\n",
    "test_X = list(test_inputs.values())[-3:]\n",
    "y_pred = (base_model.predict(test_X) > 0.5).flatten()\n",
    "print(\"Accuracy = {}\".format(round(accuracy_score(y_test, y_pred)*100, 2)))\n",
    "print(\"F1 score = {}\".format((f1_score(y_test, y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a4eb6e6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model always classifies document as non-joke\n",
    "# (non-joke is the dominant class in the 50 training examples)\n",
    "y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
